# Environment configuration for ScrapeMaster

# Application settings
NODE_ENV=development
PORT=3001
APP_NAME=ScrapeMaster Pro API
APP_VERSION=1.0.0

# Database configuration
DATABASE_URL=./data/scrapemaster.db
DATABASE_BACKUP_PATH=./backups/
DATABASE_MAX_CONNECTIONS=10

# Authentication settings
JWT_SECRET=your-jwt-secret
JWT_EXPIRATION=24h
JWT_REFRESH_EXPIRATION=7d

# Redis configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0

# Browser configuration
BROWSER_EXECUTABLE_PATH=
BROWSER_HEADLESS=true
BROWSER_TIMEOUT=30000
MAX_BROWSER_INSTANCES=5

# Rate limiting
DEFAULT_RATE_LIMIT=1000
MAX_CONCURRENT_JOBS=10
SCRAPING_RATE_LIMIT=100

# File storage
EXPORT_PATH=./exports/
TEMP_PATH=./temp/
LOG_PATH=./logs/
MAX_EXPORT_SIZE=100MB
MAX_FILE_AGE_DAYS=30

# Security
ENCRYPTION_KEY=your-32-character-encryption-key
CORS_ORIGIN=http://localhost:3000
HELMET_ENABLED=true

# Monitoring
LOG_LEVEL=info
METRICS_ENABLED=true
HEALTH_CHECK_INTERVAL=60000
PERFORMANCE_MONITORING=true

# External services
PROXY_ENABLED=false
PROXY_POOL_SIZE=10
NOTIFICATION_WEBHOOK_URL=
SENTRY_DSN=

# WebSocket configuration
WS_ENABLED=true
WS_HEARTBEAT_INTERVAL=25000
WS_HEARTBEAT_TIMEOUT=60000

# Job queue
QUEUE_CONCURRENCY=5
QUEUE_REMOVE_ON_COMPLETE=50
QUEUE_REMOVE_ON_FAIL=100
QUEUE_ATTEMPTS=3

# Backup configuration
BACKUP_ENABLED=true
BACKUP_INTERVAL_HOURS=24
BACKUP_RETENTION_DAYS=30
